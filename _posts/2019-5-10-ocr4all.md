---
layout: post
title: ocr4all
subtitle: OCR for Incunables
image: /images/ocr4all.jpg
excerpt_separator: <!--more-->
---
Probably the most significant step forward for quantitative (really any kind of text-oriented) research in Early Modern Latin (EML) in a long time is **ocr4all**, an OCR software that reliably converts scans of early printed books to machine-readable (and human-researchable) text, developed at the U. of Würzburg ([github.com/OCR4all](github.com/OCR4all)). High quality scans of early printed books have been abundant for some time now; that has, however, so far not translated into an increased availability of texts.
<!--more-->

## ocr4all
**ocr4all** is designed for the single user without extensive IT-knowledge or -support (i.e. me).  I have only used it with Latin texts, but the official test case is a multilingual textcorpus from the 15th/16th century, [Narragonien digital](kallimachos.de/kallimachos/index.php/Narragonien); ocr4all works independently of language and script. 

### Setup
*ocr4all* comes with a setup-guide that simply works - which is not my experience with open source software generally. There are user guides in several dimensions for all temperaments; I confess I am best acquainted with the shortest one (and not very well with that one). I started out with Windows 7 and switched to Windows 10; as far as I can tell there is no difference in use. 

### Use and Results
*ocr4all* has a graphical user interface and runs in the browser; I use *Chrome*. Results depend on several variables. 

#### Quality of the Scans
*ocr4all* is not demanding, but more contrast is better. Even though I have often read Sweynheym & Pannartz prints from the early 1470s on paper, I never realized that their font lacks i-dots; that does not help (at least that was my experience; probably more training would have helped). As soon as you get into the 1480s, the typeface becomes rapidly less of a factor, and a print by Froben or Jean Petit will be easily legible for *ocr4all*. I have not yet tried any of Aldus' books set in the 'Aldine' italics. 

#### Preparation of the pages
*ocr4all* copes with sophisticated types of layout, columns, inserted graphics, etc. I have tried to eliminate problems in advance by preparing the pages with *ScanTailor* (deskew, split columns, remove marginalia) and *IrfanView* (cut out graphics, initials). But that is mainly because I am familiar with these programs.

#### Training
*ocr4all* has a pretrained set of generic font models (it is able to read fraktur, though I have not tried that yet). Recognition accuracy begins in the 96% percentile, but will get up to 98% percent (and with later 16th and 17th century books probably over 99%), if you invest some time in training the model on your specific typeface. Three to four pages, twice repeated with different pages, were enough to bring the 1500 *Apuleius commentary* of Beroaldo to over 98% accuracy, which means about half an hour's investment. I have made no attempt at training or recognizing Greek. It may be worth your while to select the pages for training with care if you have a text where the letters 'y' (sometimes recognized as 'v') and 'z' (often not recognized at all) are important. I found this out the hard way with the *Antiquitates* of Annius of Viterbo (Romae 1498), where toponyms with 'z' got mangled. The problem is to find the right pages, since few words have a 'z'.

#### Use
There are lots of possibilities to tweak the program, but so far I have been content with the default settings. 

*ocr4all* does not use a dictionary (as OCR programs for modern texts usually do) - which for EML does not exist - , but uses a 'short memory' approach which I cannot claim to understand, but which works. On the average office computer *ocr4all* is not fast, fifty pages will certainly take me over an hour, and (depending on the number of lines) probably more like two, but the program runs happily in the background. My private laptop as well as my office PC are senior citizens, so yours may be faster.

#### Result
The result is a text file (unicode) which contains a precise representation of the original, line for line. *ocr4all* distinguishes reliably (and without training!) between 'f' and the 'long s' (which makes it a prime choice for books up to the 1850s, whose typeface is otherwise unproblematic). Abbreviations are rendered as on the printed page, *ocr4all* makes no attempt at guessing what an abbreviation might stand for. Anybody who has ever been puzzled by 'aim', 'aunt' (for 'animi', 'autem') and similar monsters will be grateful for this. 
 
#### Postprocessing
Since I have mostly dealt with books with extensive and ambiguous (per/par, con/com!) abbreviations and lots of words split without hyphens, postprocessing (search-and-replace) has normally taken me more time than ocr'ing the texts. I look forward to a few seventeenth century or later books without abbreviations.

#### Ease of Use
I did not find the learning curve steep. From time to time there are glitches (mostly probably due to the limitations of my elderly PC) which can only be solved by a restart. So far I have never actually lost any work, *ocr4all* seems to write everything to the harddisk immediately. 

At the moment, I have the same sense of wonder I had when I first entered the Vatican Library many years ago: when it slowly dawned on me that just about everything I might want to read was within arms length. My research largely depends on machine-readable EML texts, and the major limitation, that many texts simply are not available, has now been removed.

### Literature
Christian Reul, Uwe Springmann, Frank Puppe, LAREX – A semi-automatic open-source Tool for Layout Analysis and Region Extraction on Early Printed Books. In Proceedings of the 2nd International Conference on Digital Access to Textual Cultural Heritage (2017). 
[arxiv.org/abs/1701.07396](https://arxiv.org/abs/1701.07396) with further literature. 
